{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "womp womp\n",
      "time: 0 ns (started: 2023-12-15 11:09:12 -05:00)\n"
     ]
    }
   ],
   "source": [
    "print(\"womp womp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autotime extension is already loaded. To reload it, use:\n",
      "  %reload_ext autotime\n",
      "time: 0 ns (started: 2023-12-15 11:09:12 -05:00)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch.optim as optim\n",
    "from collections import OrderedDict\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score\n",
    "\n",
    "%load_ext autotime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>ChestPainType</th>\n",
       "      <th>RestingBP</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>FastingBS</th>\n",
       "      <th>RestingECG</th>\n",
       "      <th>MaxHR</th>\n",
       "      <th>ExerciseAngina</th>\n",
       "      <th>Oldpeak</th>\n",
       "      <th>ST_Slope</th>\n",
       "      <th>HeartDisease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40</td>\n",
       "      <td>M</td>\n",
       "      <td>ATA</td>\n",
       "      <td>140</td>\n",
       "      <td>289</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>172</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Up</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49</td>\n",
       "      <td>F</td>\n",
       "      <td>NAP</td>\n",
       "      <td>160</td>\n",
       "      <td>180</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>156</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Flat</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>M</td>\n",
       "      <td>ATA</td>\n",
       "      <td>130</td>\n",
       "      <td>283</td>\n",
       "      <td>0</td>\n",
       "      <td>ST</td>\n",
       "      <td>98</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Up</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48</td>\n",
       "      <td>F</td>\n",
       "      <td>ASY</td>\n",
       "      <td>138</td>\n",
       "      <td>214</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>108</td>\n",
       "      <td>Y</td>\n",
       "      <td>1.5</td>\n",
       "      <td>Flat</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54</td>\n",
       "      <td>M</td>\n",
       "      <td>NAP</td>\n",
       "      <td>150</td>\n",
       "      <td>195</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>122</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Up</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age Sex ChestPainType  RestingBP  Cholesterol  FastingBS RestingECG  MaxHR  \\\n",
       "0   40   M           ATA        140          289          0     Normal    172   \n",
       "1   49   F           NAP        160          180          0     Normal    156   \n",
       "2   37   M           ATA        130          283          0         ST     98   \n",
       "3   48   F           ASY        138          214          0     Normal    108   \n",
       "4   54   M           NAP        150          195          0     Normal    122   \n",
       "\n",
       "  ExerciseAngina  Oldpeak ST_Slope  HeartDisease  \n",
       "0              N      0.0       Up             0  \n",
       "1              N      1.0     Flat             1  \n",
       "2              N      0.0       Up             0  \n",
       "3              Y      1.5     Flat             1  \n",
       "4              N      0.0       Up             0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0 ns (started: 2023-12-15 11:09:12 -05:00)\n"
     ]
    }
   ],
   "source": [
    "file_path = r\"C:\\Users\\aaron\\Documents\\Python Code\\Datasets\\Heart Failure Prediction\\heart.csv\"\n",
    "\n",
    "heart_attack = pd.read_csv(file_path)\n",
    "\n",
    "heart_attack.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0 ns (started: 2023-12-15 11:09:12 -05:00)\n"
     ]
    }
   ],
   "source": [
    "#Defining mapping function to map multiple inputs of the dataset\n",
    "def gender_map(x):\n",
    "    return x.map({'M': 1, 'F': 0, 'Male' : 1, \"Female\" : 0, '1' : 1, '0' : 0})\n",
    "\n",
    "def hemisphere_map(x):\n",
    "    return x.map({'Southern Hemisphere' : -1, 'Northern Hemisphere' : 1})\n",
    "\n",
    "def countries_map(x):\n",
    "    return x.map({'Argentina' : -1, 'Brazil' : -1, 'China' : -1, 'Colombia' : -1,\n",
    "    'India' : -1, 'Nigeria' : -1, 'South Africa' : -1, 'South Korea' : -1, 'Thailand' : -1,\n",
    "    'Vietnam' : -1, 'Australia' : 1, 'Canada' : 1, 'France' : 1, 'Germany' : 1,\n",
    "    'Italy' : 1, 'Japan' : 1, 'New Zealand' : 1, 'Spain' : 1, 'United Kingdom' : 1,\n",
    "    'United States' : 1})\n",
    "\n",
    "def diet_map(x):\n",
    "    return x.map({'Unhealthy' : -1, 'Average' : 0, 'Healthy' : 1})\n",
    "\n",
    "def continent_map(x):\n",
    "    return x.map({'Asia' : 0, 'Africa' : 1, 'Europe' : 2, 'North America' : 3,\n",
    "    'South America' : 4, 'Australia' : 5})\n",
    "\n",
    "def ExerciseAngina_map(x):\n",
    "    return x.map({'Y' : 1, 'N' : 0})\n",
    "\n",
    "def ST_Slope_map(x):\n",
    "    return x.map({'Down' : -1, 'Flat' : 0, 'Up' : 1})\n",
    "\n",
    "\n",
    "def ChestPainType_map(x):\n",
    "    return x.map({'ATA' : 1, 'NAP' : 0.5, 'ASY' : -0.5, 'TA' : -1})\n",
    "\n",
    "def RestingECG_map(x):\n",
    "    return x.map({'LVH' : -1, 'Normal' : 0, 'ST' : 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 15 ms (started: 2023-12-15 11:09:12 -05:00)\n"
     ]
    }
   ],
   "source": [
    "heart_attack['Sex'] = heart_attack[['Sex']].apply(gender_map)\n",
    "heart_attack['ExerciseAngina'] = heart_attack[['ExerciseAngina']].apply(ExerciseAngina_map)\n",
    "heart_attack['ST_Slope'] = heart_attack[['ST_Slope']].apply(ST_Slope_map)\n",
    "heart_attack['ChestPainType'] = heart_attack[['ChestPainType']].apply(ChestPainType_map)\n",
    "heart_attack['RestingECG'] = heart_attack[['RestingECG']].apply(RestingECG_map)\n",
    "# heart_attack['Hemisphere'] = heart_attack[['Hemisphere']].apply(hemisphere_map)\n",
    "# heart_attack['Country'] = heart_attack[['Country']].apply(countries_map)\n",
    "# heart_attack['Diet'] = heart_attack[['Diet']].apply(diet_map)\n",
    "# heart_attack['Continent'] = heart_attack[['Continent']].apply(continent_map)\n",
    "\n",
    "# unique_sex = heart_attack['Sex'].unique()\n",
    "# print(unique_sex)\n",
    "# unique = heart_attack['Hemisphere'].unique()\n",
    "# print(unique)\n",
    "# unique_country = heart_attack['Country'].unique()\n",
    "# print(unique_country)\n",
    "# unique_diet = heart_attack['Diet'].unique()\n",
    "# print(unique_diet)\n",
    "# unique_continent = heart_attack['Continent'].unique()\n",
    "# print(unique_continent)\n",
    "\n",
    "# heart_attack.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with NaN values after fillna operations:\n",
      "[]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>ChestPainType</th>\n",
       "      <th>RestingBP</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>FastingBS</th>\n",
       "      <th>RestingECG</th>\n",
       "      <th>MaxHR</th>\n",
       "      <th>ExerciseAngina</th>\n",
       "      <th>Oldpeak</th>\n",
       "      <th>ST_Slope</th>\n",
       "      <th>HeartDisease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>140</td>\n",
       "      <td>289</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>160</td>\n",
       "      <td>180</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>156</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>130</td>\n",
       "      <td>283</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>98</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>138</td>\n",
       "      <td>214</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>108</td>\n",
       "      <td>1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>150</td>\n",
       "      <td>195</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>122</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Sex  ChestPainType  RestingBP  Cholesterol  FastingBS  RestingECG  \\\n",
       "0   40    1            1.0        140          289          0           0   \n",
       "1   49    0            0.5        160          180          0           0   \n",
       "2   37    1            1.0        130          283          0           1   \n",
       "3   48    0           -0.5        138          214          0           0   \n",
       "4   54    1            0.5        150          195          0           0   \n",
       "\n",
       "   MaxHR  ExerciseAngina  Oldpeak  ST_Slope  HeartDisease  \n",
       "0    172               0      0.0         1             0  \n",
       "1    156               0      1.0         0             1  \n",
       "2     98               0      0.0         1             0  \n",
       "3    108               1      1.5         0             1  \n",
       "4    122               0      0.0         1             0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 16 ms (started: 2023-12-15 11:09:12 -05:00)\n"
     ]
    }
   ],
   "source": [
    "# mode_columns = ['Stress Level','Medication Use', 'Previous Heart Problems', 'Diet', 'Physical Activity Days Per Week', 'Alcohol Consumption', 'Obesity', 'Smoking', \n",
    "#                 'Family History', 'Diabetes', 'Hemisphere', 'Continent', 'Country']\n",
    "\n",
    "# mean_columns = ['Exercise Hours Per Week', 'Sleep Hours Per Day', 'BMI', 'Sedentary Hours Per Day']\n",
    "\n",
    "# median_columns = ['Heart Rate', 'Income', 'Triglycerides']\n",
    "\n",
    "# # Fill NaN values with the mode of the column for mode_columns\n",
    "# for col in mode_columns:\n",
    "#     heart_attack[col].fillna(heart_attack[col].mode()[0], inplace=True)\n",
    "\n",
    "# # Fill NaN values with the median of the column for median_columns\n",
    "# for col in median_columns:\n",
    "#     heart_attack[col].fillna(heart_attack[col].median(), inplace=True)\n",
    "\n",
    "# # Fill NaN values with the mean of the column for mean_columns\n",
    "# for col in mean_columns:\n",
    "#     heart_attack[col].fillna(heart_attack[col].mean(), inplace=True)\n",
    "\n",
    "\n",
    "# unique_sex = heart_attack['Sex'].unique()\n",
    "# print(unique_sex)\n",
    "# unique = heart_attack['Hemisphere'].unique()\n",
    "# print(unique)\n",
    "# unique_country = heart_attack['Country'].unique()\n",
    "# print(unique_country)\n",
    "# unique_diet = heart_attack['Diet'].unique()\n",
    "# print(unique_diet)\n",
    "# unique_continent = heart_attack['Continent'].unique()\n",
    "# print(unique_continent)\n",
    "\n",
    "\n",
    "# Check for NaN values in columns after fillna operations\n",
    "columns_with_nulls = heart_attack.columns[heart_attack.isnull().any()].tolist()\n",
    "print(\"Columns with NaN values after fillna operations:\")\n",
    "print(columns_with_nulls)\n",
    "\n",
    "heart_attack.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is not available, using CPU.\n",
      "time: 0 ns (started: 2023-12-15 11:09:12 -05:00)\n"
     ]
    }
   ],
   "source": [
    "# Check if GPU is available\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")  # Use GPU\n",
    "    print(\"GPU is available.\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")   # Use CPU\n",
    "    print(\"GPU is not available, using CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n",
      "torch.float32\n",
      "time: 15 ms (started: 2023-12-15 11:09:12 -05:00)\n"
     ]
    }
   ],
   "source": [
    "#Splitting the Variables into X and Y\n",
    "X = heart_attack.iloc[:, 0:10].values\n",
    "Y = heart_attack.iloc[:, 11].values\n",
    "\n",
    "# Split our Data set into Training Data and val Data.\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size = 0.2, random_state = 0)\n",
    "\n",
    "Y_train = Y_train.reshape(-1, 1)\n",
    "Y_val = Y_val.reshape(-1, 1)\n",
    "\n",
    "# Convert the numpy arrays into tensors\n",
    "Y_train_t = torch.tensor(Y_train, dtype=torch.float)\n",
    "Y_val_t = torch.tensor(Y_val, dtype=torch.float)\n",
    "\n",
    "\n",
    "print(Y_train_t.dtype)\n",
    "print(Y_val_t.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0 ns (started: 2023-12-15 11:09:12 -05:00)\n"
     ]
    }
   ],
   "source": [
    "# Defining PCA function\n",
    "def PCA_function(X_train, X_val, K):\n",
    "  pca = PCA(n_components=K)\n",
    "  X_train_PCA = pca.fit_transform(X_train)\n",
    "  X_val_PCA = pca.fit_transform(X_val)\n",
    "  return X_train_PCA, X_val_PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of X_train after PCA is (734, 2)\n",
      "The shape of X_val after PCA is (184, 2)\n",
      "\n",
      "The shape of the X_train tensor is torch.Size([734, 2])\n",
      "The shape of the X_val tensor is torch.Size([184, 2])\n",
      "time: 16 ms (started: 2023-12-15 11:09:12 -05:00)\n"
     ]
    }
   ],
   "source": [
    "(X_train_PCA, X_val_PCA) = PCA_function(X_train, X_val, 2)\n",
    "\n",
    "print(\"The shape of X_train after PCA is\", X_train_PCA.shape)\n",
    "print(\"The shape of X_val after PCA is\", X_val_PCA.shape)\n",
    "\n",
    "# Use standard scaling from Sklearn to scale data between - and  for better accuracy.\n",
    "scale = StandardScaler()\n",
    "X_train_PCA = scale.fit_transform(X_train_PCA)\n",
    "X_val_PCA = scale.fit_transform(X_val_PCA)\n",
    "\n",
    "X_train_PCA_t = torch.tensor(X_train_PCA, dtype=torch.float)\n",
    "X_val_PCA_t = torch.tensor(X_val_PCA, dtype=torch.float)\n",
    "\n",
    "print(\"\\nThe shape of the X_train tensor is\", X_train_PCA_t.shape)\n",
    "print(\"The shape of the X_val tensor is\", X_val_PCA_t.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0 ns (started: 2023-12-15 11:09:12 -05:00)\n"
     ]
    }
   ],
   "source": [
    "def model_linear(t_in, w1, w2, w3, b):\n",
    "  t_p = ((w3 * t_in ** 3) + (w2 * t_in ** 2) + (w1 * t_in) + b)\n",
    "  return t_p\n",
    "\n",
    "def loss_fn(t_p, t_gnd):\n",
    "  squared_diffs = (t_p - t_gnd)**2\n",
    "  return squared_diffs.mean()\n",
    "\n",
    "def training_loop(n_epochs, optimizer, params, train_t_in, val_t_in,\n",
    "                    train_t_out, val_t_out):\n",
    "  for epoch in range(1, n_epochs + 1):\n",
    "\n",
    "    if params.grad is not None:\n",
    "      params.grad.zero_()\n",
    "\n",
    "    train_t_p = model_linear(train_t_in, *params)\n",
    "    train_loss = loss_fn(train_t_p, train_t_out)\n",
    "\n",
    "    val_t_p = model_linear(val_t_in, *params)\n",
    "    val_loss = loss_fn(val_t_p, val_t_out)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    train_loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch <= 3 or epoch % 500 == 0:\n",
    "      print(f\"Epoch {epoch}, \\tTraining loss {train_loss.item():.4f},\"\n",
    "      f\" \\tValidation loss {val_loss.item():.4f}\")\n",
    "\n",
    "  return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss every 500 epochs using learning rate of 1e-3\n",
      "\n",
      "Epoch 1, \tTraining loss 21.6165, \tValidation loss 17.4866\n",
      "Epoch 2, \tTraining loss 20.5279, \tValidation loss 16.6155\n",
      "Epoch 3, \tTraining loss 19.4978, \tValidation loss 15.7913\n",
      "Epoch 500, \tTraining loss 0.3871, \tValidation loss 0.4637\n",
      "Epoch 1000, \tTraining loss 0.3155, \tValidation loss 0.3772\n",
      "Epoch 1500, \tTraining loss 0.2807, \tValidation loss 0.3300\n",
      "Epoch 2000, \tTraining loss 0.2616, \tValidation loss 0.3018\n",
      "Epoch 2500, \tTraining loss 0.2506, \tValidation loss 0.2840\n",
      "Epoch 3000, \tTraining loss 0.2441, \tValidation loss 0.2724\n",
      "Epoch 3500, \tTraining loss 0.2402, \tValidation loss 0.2645\n",
      "Epoch 4000, \tTraining loss 0.2378, \tValidation loss 0.2592\n",
      "Epoch 4500, \tTraining loss 0.2364, \tValidation loss 0.2554\n",
      "Epoch 5000, \tTraining loss 0.2355, \tValidation loss 0.2528\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 0.2330,  0.0965, -0.0529,  0.4282], requires_grad=True)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.48 s (started: 2023-12-15 11:09:12 -05:00)\n"
     ]
    }
   ],
   "source": [
    "params = torch.tensor([1.0, 1.0, 1.0, 0.0], requires_grad=True)\n",
    "\n",
    "learning_rate_1 = 1e-3\n",
    "optimizer_1 = optim.SGD([params], lr=learning_rate_1)\n",
    "\n",
    "print('Loss every 500 epochs using learning rate of 1e-3\\n')\n",
    "training_loop(\n",
    "    n_epochs = 5000,\n",
    "    optimizer = optimizer_1,\n",
    "    params = params,\n",
    "    train_t_in = X_train_PCA_t,\n",
    "    val_t_in = X_val_PCA_t,\n",
    "    train_t_out = Y_train_t,\n",
    "    val_t_out = Y_val_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.5654\n",
      "Training Precision: 0.5814\n",
      "Training Recall: 0.5773\n",
      "Training F1 Score: 0.5793\n",
      "\n",
      "Validation Accuracy: 0.5054\n",
      "Validation Precision: 0.5264\n",
      "Validation Recall: 0.5256\n",
      "Validation F1 Score: 0.5260\n",
      "time: 0 ns (started: 2023-12-15 11:09:14 -05:00)\n"
     ]
    }
   ],
   "source": [
    "# Getting the predictions based on the training set using the linear model\n",
    "model_output = model_linear(X_train_PCA_t, *params)\n",
    "# Converting the prediction tensor into a numpy array to use the sklearn metrics library\n",
    "model_output_np = model_output.detach().numpy() if isinstance(model_output, torch.Tensor) else model_output\n",
    "\n",
    "# Using argmax to get the class (1 or 0) with the highest probability\n",
    "predicted_labels = np.argmax(model_output_np, axis=1)\n",
    "\n",
    "# Calculate accuracy, precision, and recall for training set\n",
    "train_accuracy = accuracy_score(Y_train, predicted_labels)\n",
    "train_recall = recall_score(Y_train, predicted_labels, average= 'macro', zero_division=1)\n",
    "train_precision = precision_score(Y_train, predicted_labels, average = 'macro', zero_division=1)\n",
    "train_F1_score = (2*train_recall*train_precision)/(train_recall+train_precision)\n",
    "\n",
    "# Getting the predictions based on the validation set using the linear model\n",
    "model_output_val = model_linear(X_val_PCA_t, *params)\n",
    "# Converting the prediction tensor into a numpy array to use the sklearn metrics library\n",
    "model_output_val_np = model_output_val.detach().numpy() if isinstance(model_output_val, torch.Tensor) else model_output_val\n",
    "\n",
    "# Using argmax to get the class (1 or 0) with the highest probability\n",
    "predicted_labels_val = np.argmax(model_output_val_np, axis=1)\n",
    "\n",
    "# Calculate accuracy, precision, and recall for validation set\n",
    "val_accuracy = accuracy_score(Y_val, predicted_labels_val)\n",
    "val_precision = precision_score(Y_val, predicted_labels_val, average = 'macro', zero_division=1)\n",
    "val_recall = recall_score(Y_val, predicted_labels_val, average = 'macro', zero_division=1)\n",
    "val_F1_score = (2*val_recall*val_precision)/(val_recall+val_precision)\n",
    "\n",
    "# Print the calculated metrics\n",
    "print(f\"Training Accuracy: {train_accuracy:.4f}\")\n",
    "print(f\"Training Precision: {train_precision:.4f}\")\n",
    "print(f\"Training Recall: {train_recall:.4f}\")\n",
    "print(f\"Training F1 Score: {train_F1_score:.4f}\")\n",
    "\n",
    "print(f\"\\nValidation Accuracy: {val_accuracy:.4f}\")\n",
    "print(f\"Validation Precision: {val_precision:.4f}\")\n",
    "print(f\"Validation Recall: {val_recall:.4f}\")\n",
    "print(f\"Validation F1 Score: {val_F1_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=2, out_features=1024, bias=True)\n",
       "  (1): Tanh()\n",
       "  (2): Linear(in_features=1024, out_features=2048, bias=True)\n",
       "  (3): Tanh()\n",
       "  (4): Linear(in_features=2048, out_features=512, bias=True)\n",
       "  (5): Tanh()\n",
       "  (6): Linear(in_features=512, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 16 ms (started: 2023-12-15 11:09:14 -05:00)\n"
     ]
    }
   ],
   "source": [
    "#Sequential Model\n",
    "\n",
    "model_seq = nn.Sequential(\n",
    "    nn.Linear(2, 1024),\n",
    "    nn.Tanh(),\n",
    "    nn.Linear(1024, 2048),\n",
    "    nn.Tanh(),\n",
    "    nn.Linear(2048, 512),\n",
    "    nn.Tanh(),\n",
    "    nn.Linear(512, 1)\n",
    "            )\n",
    "model_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3151873"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0 ns (started: 2023-12-15 11:09:14 -05:00)\n"
     ]
    }
   ],
   "source": [
    "sum([p.numel() for p in model_seq.parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0 ns (started: 2023-12-15 11:09:14 -05:00)\n"
     ]
    }
   ],
   "source": [
    "#Let's define our training loop that will be used\n",
    "\n",
    "def training_loop_seq(n_epochs, optimizer, model, loss_fn, x_train, x_val,\n",
    "                  y_train, y_val):\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        p_train = model(x_train) # <1>\n",
    "        loss_train = loss_fn(p_train, y_train,)\n",
    "\n",
    "        p_val = model(x_val) # <1>\n",
    "        loss_val = loss_fn(p_val, y_val)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss_train.backward() # <2>\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "        if epoch == 1 or epoch % 10 == 0:\n",
    "            print(f\"Epoch: {epoch}, Training loss: {loss_train.item():.4f},\"\n",
    "                  f\" Validation loss: {loss_val.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Training loss: 0.6835, Validation loss: 0.7208\n",
      "Epoch: 10, Training loss: 0.2903, Validation loss: 0.3060\n",
      "Epoch: 20, Training loss: 0.2105, Validation loss: 0.2033\n",
      "Epoch: 30, Training loss: 0.1984, Validation loss: 0.1947\n",
      "Epoch: 40, Training loss: 0.1966, Validation loss: 0.1988\n",
      "Epoch: 50, Training loss: 0.1906, Validation loss: 0.1908\n",
      "Epoch: 60, Training loss: 0.1893, Validation loss: 0.1889\n",
      "Epoch: 70, Training loss: 0.1886, Validation loss: 0.1897\n",
      "Epoch: 80, Training loss: 0.1880, Validation loss: 0.1903\n",
      "Epoch: 90, Training loss: 0.1876, Validation loss: 0.1906\n",
      "Epoch: 100, Training loss: 0.1872, Validation loss: 0.1906\n",
      "Epoch: 110, Training loss: 0.1869, Validation loss: 0.1904\n",
      "Epoch: 120, Training loss: 0.1866, Validation loss: 0.1902\n",
      "Epoch: 130, Training loss: 0.1863, Validation loss: 0.1900\n",
      "Epoch: 140, Training loss: 0.1861, Validation loss: 0.1899\n",
      "Epoch: 150, Training loss: 0.1858, Validation loss: 0.1899\n",
      "Epoch: 160, Training loss: 0.1856, Validation loss: 0.1899\n",
      "Epoch: 170, Training loss: 0.1854, Validation loss: 0.1898\n",
      "Epoch: 180, Training loss: 0.1852, Validation loss: 0.1898\n",
      "Epoch: 190, Training loss: 0.1850, Validation loss: 0.1897\n",
      "Epoch: 200, Training loss: 0.1848, Validation loss: 0.1897\n",
      "Epoch: 210, Training loss: 0.1847, Validation loss: 0.1897\n",
      "Epoch: 220, Training loss: 0.1845, Validation loss: 0.1897\n",
      "Epoch: 230, Training loss: 0.1844, Validation loss: 0.1898\n",
      "Epoch: 240, Training loss: 0.1842, Validation loss: 0.1899\n",
      "Epoch: 250, Training loss: 0.1840, Validation loss: 0.1900\n",
      "Epoch: 260, Training loss: 0.1838, Validation loss: 0.1901\n",
      "Epoch: 270, Training loss: 0.1836, Validation loss: 0.1901\n",
      "Epoch: 280, Training loss: 0.1834, Validation loss: 0.1902\n",
      "Epoch: 290, Training loss: 0.1832, Validation loss: 0.1901\n",
      "Epoch: 300, Training loss: 0.1829, Validation loss: 0.1901\n",
      "Epoch: 310, Training loss: 0.1826, Validation loss: 0.1898\n",
      "Epoch: 320, Training loss: 0.1838, Validation loss: 0.1926\n",
      "Epoch: 330, Training loss: 0.1823, Validation loss: 0.1892\n",
      "Epoch: 340, Training loss: 0.1819, Validation loss: 0.1901\n",
      "Epoch: 350, Training loss: 0.1817, Validation loss: 0.1901\n",
      "Epoch: 360, Training loss: 0.1815, Validation loss: 0.1896\n",
      "Epoch: 370, Training loss: 0.1813, Validation loss: 0.1898\n",
      "Epoch: 380, Training loss: 0.1811, Validation loss: 0.1899\n",
      "Epoch: 390, Training loss: 0.1809, Validation loss: 0.1898\n",
      "Epoch: 400, Training loss: 0.1807, Validation loss: 0.1897\n",
      "Epoch: 410, Training loss: 0.1808, Validation loss: 0.1890\n",
      "Epoch: 420, Training loss: 0.1806, Validation loss: 0.1911\n",
      "Epoch: 430, Training loss: 0.1803, Validation loss: 0.1901\n",
      "Epoch: 440, Training loss: 0.1801, Validation loss: 0.1897\n",
      "Epoch: 450, Training loss: 0.1823, Validation loss: 0.1901\n",
      "Epoch: 460, Training loss: 0.1799, Validation loss: 0.1894\n",
      "Epoch: 470, Training loss: 0.1797, Validation loss: 0.1893\n",
      "Epoch: 480, Training loss: 0.1795, Validation loss: 0.1894\n",
      "Epoch: 490, Training loss: 0.1794, Validation loss: 0.1897\n",
      "Epoch: 500, Training loss: 0.1792, Validation loss: 0.1895\n",
      "time: 37.7 s (started: 2023-12-15 11:09:14 -05:00)\n"
     ]
    }
   ],
   "source": [
    "#Let's try doing some training\n",
    "\n",
    "optimizer_1 = optim.Adam(model_seq.parameters(), lr=1e-4)\n",
    "\n",
    "training_loop_seq(\n",
    "    n_epochs = 501,\n",
    "    optimizer = optimizer_1,\n",
    "    model = model_seq,\n",
    "    loss_fn = nn.MSELoss(),\n",
    "    x_train = X_train_PCA_t,\n",
    "    x_val = X_val_PCA_t,\n",
    "    y_train = Y_train_t,\n",
    "    y_val = Y_val_t\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 15 ms (started: 2023-12-15 11:09:52 -05:00)\n"
     ]
    }
   ],
   "source": [
    "# Function to calculate accuracy\n",
    "def calculate_accuracy(predictions, targets):\n",
    "    return (predictions == targets).float().mean().item()\n",
    "\n",
    "# Function to calculate recall\n",
    "def calculate_recall(predictions, targets):\n",
    "    true_positives = ((predictions == 1) & (targets == 1)).sum().item()\n",
    "    false_negatives = ((predictions == 0) & (targets == 1)).sum().item()\n",
    "    return true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0\n",
    "\n",
    "# Function to calculate precision\n",
    "def calculate_precision(predictions, targets):\n",
    "    true_positives = ((predictions == 1) & (targets == 1)).sum().item()\n",
    "    false_positives = ((predictions == 1) & (targets == 0)).sum().item()\n",
    "    return true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.5490\n",
      "Training Recall: 1.0000\n",
      "Training Precision: 0.5478\n",
      "Training F1 Score: 0.7079\n",
      "\n",
      "Validation Accuracy: 0.5978\n",
      "Validation Recall: 1.0000\n",
      "Validation Precision: 0.5912\n",
      "Validation F1 Score: 0.7431\n",
      "time: 47 ms (started: 2023-12-15 11:09:52 -05:00)\n"
     ]
    }
   ],
   "source": [
    "# Calculate predictions for the training set\n",
    "with torch.no_grad():\n",
    "    train_predictions = torch.round(torch.sigmoid(model_seq(X_train_PCA_t)))\n",
    "\n",
    "# Calculate accuracy, recall, precision, and F1 Score for the training set\n",
    "accuracy_train = calculate_accuracy(train_predictions, Y_train_t)\n",
    "recall_train = calculate_recall(train_predictions, Y_train_t)\n",
    "precision_train = calculate_precision(train_predictions, Y_train_t)\n",
    "F1_score_train = (2*recall_train*precision_train)/(recall_train+precision_train)\n",
    "\n",
    "# Calculate predictions for the validation set\n",
    "with torch.no_grad():\n",
    "    train_predictions_val = torch.round(torch.sigmoid(model_seq(X_val_PCA_t)))\n",
    "\n",
    "# Calculate accuracy, recall, precision, and F1 Score for the validation set\n",
    "accuracy_val = calculate_accuracy(train_predictions_val, Y_val_t)\n",
    "recall_val = calculate_recall(train_predictions_val, Y_val_t)\n",
    "precision_val = calculate_precision(train_predictions_val, Y_val_t)\n",
    "F1_score_val = (2*recall_val*precision_val)/(recall_val+precision_val)\n",
    "\n",
    "# Print the calculated metrics\n",
    "print(\"Training Accuracy: {:.4f}\".format(accuracy_train))\n",
    "print(\"Training Recall: {:.4f}\".format(recall_train))\n",
    "print(\"Training Precision: {:.4f}\".format(precision_train))\n",
    "print(\"Training F1 Score: {:.4f}\".format(F1_score_train))\n",
    "\n",
    "print(\"\\nValidation Accuracy: {:.4f}\".format(accuracy_val))\n",
    "print(\"Validation Recall: {:.4f}\".format(recall_val))\n",
    "print(\"Validation Precision: {:.4f}\".format(precision_val))\n",
    "print(\"Validation F1 Score: {:.4f}\".format(F1_score_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 16 ms (started: 2023-12-15 11:09:52 -05:00)\n"
     ]
    }
   ],
   "source": [
    "model_fnn = nn.Sequential(\n",
    "            nn.Linear(2, 1024),\n",
    "            nn.Tanh(),\n",
    "            nn.Dropout(p=0.5),  # Dropout layer with a dropout probability of 0.5\n",
    "            nn.Linear(1024, 2048),\n",
    "            nn.Tanh(),\n",
    "            nn.Dropout(p=0.5),  # Dropout layer with a dropout probability of 0.5\n",
    "            nn.Linear(2048,1024),\n",
    "            nn.Tanh(),\n",
    "            nn.Dropout(p=0.5),  # Dropout layer with a dropout probability of 0.5\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.Tanh(),\n",
    "            nn.Dropout(p=0.5),  # Dropout layer with a dropout probability of 0.5\n",
    "            nn.Linear(512, 64),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(64, 1)\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4758145"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0 ns (started: 2023-12-15 11:09:52 -05:00)\n"
     ]
    }
   ],
   "source": [
    "sum([p.numel() for p in model_fnn.parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 0.699251\n",
      "Epoch: 10, Loss: 0.585557\n",
      "Epoch: 20, Loss: 0.578067\n",
      "Epoch: 30, Loss: 0.584803\n",
      "Epoch: 40, Loss: 0.580392\n",
      "Epoch: 50, Loss: 0.604798\n",
      "Epoch: 60, Loss: 0.568092\n",
      "Epoch: 70, Loss: 0.572756\n",
      "Epoch: 80, Loss: 0.571979\n",
      "Epoch: 90, Loss: 0.565025\n",
      "Epoch: 100, Loss: 0.574840\n",
      "Epoch: 110, Loss: 0.569844\n",
      "Epoch: 120, Loss: 0.570944\n",
      "Epoch: 130, Loss: 0.563022\n",
      "Epoch: 140, Loss: 0.558242\n",
      "Epoch: 150, Loss: 0.562389\n",
      "Epoch: 160, Loss: 0.565654\n",
      "Epoch: 170, Loss: 0.560983\n",
      "Epoch: 180, Loss: 0.559264\n",
      "Epoch: 190, Loss: 0.559316\n",
      "Epoch: 200, Loss: 0.556369\n",
      "Epoch: 210, Loss: 0.557863\n",
      "Epoch: 220, Loss: 0.561548\n",
      "Epoch: 230, Loss: 0.556681\n",
      "Epoch: 240, Loss: 0.561481\n",
      "Epoch: 250, Loss: 0.560376\n",
      "Epoch: 260, Loss: 0.555600\n",
      "Epoch: 270, Loss: 0.558778\n",
      "Epoch: 280, Loss: 0.560203\n",
      "Epoch: 290, Loss: 0.557231\n",
      "Epoch: 300, Loss: 0.559874\n",
      "Epoch: 310, Loss: 0.552773\n",
      "Epoch: 320, Loss: 0.555220\n",
      "Epoch: 330, Loss: 0.554105\n",
      "Epoch: 340, Loss: 0.556662\n",
      "Epoch: 350, Loss: 0.555707\n",
      "Epoch: 360, Loss: 0.555429\n",
      "Epoch: 370, Loss: 0.553280\n",
      "Epoch: 380, Loss: 0.553823\n",
      "Epoch: 390, Loss: 0.553202\n",
      "Epoch: 400, Loss: 0.560478\n",
      "Epoch: 410, Loss: 0.554278\n",
      "Epoch: 420, Loss: 0.550440\n",
      "Epoch: 430, Loss: 0.551415\n",
      "Epoch: 440, Loss: 0.553822\n",
      "Epoch: 450, Loss: 0.555560\n",
      "Epoch: 460, Loss: 0.556481\n",
      "Epoch: 470, Loss: 0.557624\n",
      "Epoch: 480, Loss: 0.553820\n",
      "Epoch: 490, Loss: 0.554495\n",
      "Epoch: 500, Loss: 0.549967\n",
      "Epoch: 510, Loss: 0.546849\n",
      "Epoch: 520, Loss: 0.555549\n",
      "Epoch: 530, Loss: 0.552057\n",
      "Epoch: 540, Loss: 0.551158\n",
      "Epoch: 550, Loss: 0.555831\n",
      "Epoch: 560, Loss: 0.551907\n",
      "Epoch: 570, Loss: 0.551542\n",
      "Epoch: 580, Loss: 0.554024\n",
      "Epoch: 590, Loss: 0.549839\n",
      "Epoch: 600, Loss: 0.551133\n",
      "Epoch: 610, Loss: 0.548507\n",
      "Epoch: 620, Loss: 0.551812\n",
      "Epoch: 630, Loss: 0.555177\n",
      "Epoch: 640, Loss: 0.553962\n",
      "Epoch: 650, Loss: 0.549938\n",
      "Epoch: 660, Loss: 0.552724\n",
      "Epoch: 670, Loss: 0.550582\n",
      "Epoch: 680, Loss: 0.545757\n",
      "Epoch: 690, Loss: 0.548658\n",
      "Epoch: 700, Loss: 0.549073\n",
      "Epoch: 710, Loss: 0.545122\n",
      "Epoch: 720, Loss: 0.549447\n",
      "Epoch: 730, Loss: 0.551504\n",
      "Epoch: 740, Loss: 0.553435\n",
      "Epoch: 750, Loss: 0.549685\n",
      "Epoch: 760, Loss: 0.548044\n",
      "Epoch: 770, Loss: 0.547716\n",
      "Epoch: 780, Loss: 0.549589\n",
      "Epoch: 790, Loss: 0.545650\n",
      "Epoch: 800, Loss: 0.549877\n",
      "Epoch: 810, Loss: 0.548846\n",
      "Epoch: 820, Loss: 0.545561\n",
      "Epoch: 830, Loss: 0.547680\n",
      "Epoch: 840, Loss: 0.549473\n",
      "Epoch: 850, Loss: 0.544221\n",
      "Epoch: 860, Loss: 0.547995\n",
      "Epoch: 870, Loss: 0.545793\n",
      "Epoch: 880, Loss: 0.551412\n",
      "Epoch: 890, Loss: 0.546738\n",
      "Epoch: 900, Loss: 0.547384\n",
      "Epoch: 910, Loss: 0.549188\n",
      "Epoch: 920, Loss: 0.545501\n",
      "Epoch: 930, Loss: 0.550492\n",
      "Epoch: 940, Loss: 0.548469\n",
      "Epoch: 950, Loss: 0.545879\n",
      "Epoch: 960, Loss: 0.549103\n",
      "Epoch: 970, Loss: 0.550330\n",
      "Epoch: 980, Loss: 0.548350\n",
      "Epoch: 990, Loss: 0.546636\n",
      "Epoch: 1000, Loss: 0.553128\n",
      "Epoch: 1010, Loss: 0.546114\n",
      "Epoch: 1020, Loss: 0.541849\n",
      "Epoch: 1030, Loss: 0.539578\n",
      "Epoch: 1040, Loss: 0.546669\n",
      "Epoch: 1050, Loss: 0.545177\n",
      "Epoch: 1060, Loss: 0.544523\n",
      "Epoch: 1070, Loss: 0.555634\n",
      "Epoch: 1080, Loss: 0.541728\n",
      "Epoch: 1090, Loss: 0.548261\n",
      "Epoch: 1100, Loss: 0.549948\n",
      "Epoch: 1110, Loss: 0.546357\n",
      "Epoch: 1120, Loss: 0.541516\n",
      "Epoch: 1130, Loss: 0.546812\n",
      "Epoch: 1140, Loss: 0.544779\n",
      "Epoch: 1150, Loss: 0.545570\n",
      "Epoch: 1160, Loss: 0.542876\n",
      "Epoch: 1170, Loss: 0.543973\n",
      "Epoch: 1180, Loss: 0.547641\n",
      "Epoch: 1190, Loss: 0.542630\n",
      "Epoch: 1200, Loss: 0.545904\n",
      "Epoch: 1210, Loss: 0.541204\n",
      "Epoch: 1220, Loss: 0.541251\n",
      "Epoch: 1230, Loss: 0.542191\n",
      "Epoch: 1240, Loss: 0.549053\n",
      "Epoch: 1250, Loss: 0.545079\n",
      "Epoch: 1260, Loss: 0.542853\n",
      "Epoch: 1270, Loss: 0.549871\n",
      "Epoch: 1280, Loss: 0.544758\n",
      "Epoch: 1290, Loss: 0.548462\n",
      "Epoch: 1300, Loss: 0.541631\n",
      "Epoch: 1310, Loss: 0.540177\n",
      "Epoch: 1320, Loss: 0.537991\n",
      "Epoch: 1330, Loss: 0.545940\n",
      "Epoch: 1340, Loss: 0.540625\n",
      "Epoch: 1350, Loss: 0.546218\n",
      "Epoch: 1360, Loss: 0.547016\n",
      "Epoch: 1370, Loss: 0.540959\n",
      "Epoch: 1380, Loss: 0.536580\n",
      "Epoch: 1390, Loss: 0.545709\n",
      "Epoch: 1400, Loss: 0.546117\n",
      "Epoch: 1410, Loss: 0.536501\n",
      "Epoch: 1420, Loss: 0.536147\n",
      "Epoch: 1430, Loss: 0.541925\n",
      "Epoch: 1440, Loss: 0.545415\n",
      "Epoch: 1450, Loss: 0.544541\n",
      "Epoch: 1460, Loss: 0.538260\n",
      "Epoch: 1470, Loss: 0.537882\n",
      "Epoch: 1480, Loss: 0.539686\n",
      "Epoch: 1490, Loss: 0.542350\n",
      "Epoch: 1500, Loss: 0.545313\n",
      "time: 2min 32s (started: 2023-12-15 11:09:52 -05:00)\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1\n",
    "\n",
    "optimizer = optim.SGD(model_fnn.parameters(), lr=learning_rate)\n",
    "\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "n_epochs = 1501\n",
    "\n",
    "#This is the Training\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    outputs = model_fnn(X_train_PCA_t)\n",
    "    loss = loss_fn(outputs, Y_train_t)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 10 == 0:  # Print loss every 10 epochs\n",
    "      print(\"Epoch: %d, Loss: %f\" % (epoch, float(loss)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.453678\n",
      "Training Precision: 0.226839\n",
      "Training Recall: 0.500000\n",
      "Training F1 score: 0.312090\n",
      "time: 46 ms (started: 2023-12-15 11:12:24 -05:00)\n"
     ]
    }
   ],
   "source": [
    "# Checking the Accuracy, Recall, Precision, and F1 Score of the Training Set\n",
    "\n",
    "correct_train = 0\n",
    "total_train = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs_train = model_fnn(X_train_PCA_t)\n",
    "    _, predicted_train = torch.max(outputs_train, dim=1)\n",
    "    total_train += Y_train_t.size(0)\n",
    "    correct_train += int((predicted_train == Y_train_t.squeeze()).sum())\n",
    "\n",
    "accuracy_train = correct_train / total_train\n",
    "precision_train = precision_score(Y_train_t, predicted_train, average='macro', zero_division=0)\n",
    "recall_train = recall_score(Y_train_t, predicted_train, average='macro', zero_division=0)\n",
    "F1_score_train = (2*recall_train*precision_train)/(recall_train+precision_train)\n",
    "\n",
    "# Print the metrics\n",
    "print(\"Training Accuracy: %f\" % accuracy_train)\n",
    "print(\"Training Precision: %f\" % precision_train)\n",
    "print(\"Training Recall: %f\" % recall_train)\n",
    "print(\"Training F1 score: %f\" % F1_score_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.418478\n",
      "Training Precision: 0.209239\n",
      "Training Recall: 0.500000\n",
      "Training F1 score: 0.295019\n",
      "time: 16 ms (started: 2023-12-15 11:12:24 -05:00)\n"
     ]
    }
   ],
   "source": [
    "# Checking the Accuracy, Recall, Precision, and F1 Score of the Validation Set\n",
    "\n",
    "correct_val = 0\n",
    "total_val = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs_val = model_fnn(X_val_PCA_t)\n",
    "    _, predicted_val = torch.max(outputs_val, dim=1)\n",
    "    total_val += Y_val_t.size(0)\n",
    "    correct_val += int((predicted_val == Y_val_t.squeeze()).sum())\n",
    "\n",
    "accuracy_val = correct_val / total_val\n",
    "precision_val = precision_score(Y_val_t, predicted_val, average='macro', zero_division=0)\n",
    "recall_val = recall_score(Y_val_t, predicted_val, average='macro', zero_division=0)\n",
    "F1_score_val = (2*recall_val*precision_val)/(recall_val+precision_val)\n",
    "\n",
    "# Print the metrics\n",
    "print(\"Validation Accuracy: %f\" % accuracy_val)\n",
    "print(\"Training Precision: %f\" % precision_val)\n",
    "print(\"Training Recall: %f\" % recall_val)\n",
    "print(\"Training F1 score: %f\" % F1_score_val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
