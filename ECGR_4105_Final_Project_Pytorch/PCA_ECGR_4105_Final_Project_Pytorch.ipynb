{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "womp womp\n"
     ]
    }
   ],
   "source": [
    "print(\"womp womp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0 ns (started: 2023-12-10 21:04:34 -05:00)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch.optim as optim\n",
    "from collections import OrderedDict\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score\n",
    "\n",
    "%load_ext autotime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Blood Pressure</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>Heart Rate</th>\n",
       "      <th>Diabetes</th>\n",
       "      <th>Family History</th>\n",
       "      <th>Smoking</th>\n",
       "      <th>Obesity</th>\n",
       "      <th>Alcohol Consumption</th>\n",
       "      <th>...</th>\n",
       "      <th>Sedentary Hours Per Day</th>\n",
       "      <th>Income</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Triglycerides</th>\n",
       "      <th>Physical Activity Days Per Week</th>\n",
       "      <th>Sleep Hours Per Day</th>\n",
       "      <th>Country</th>\n",
       "      <th>Continent</th>\n",
       "      <th>Hemisphere</th>\n",
       "      <th>Heart Risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40</td>\n",
       "      <td>M</td>\n",
       "      <td>140</td>\n",
       "      <td>289</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49</td>\n",
       "      <td>F</td>\n",
       "      <td>160</td>\n",
       "      <td>180</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>M</td>\n",
       "      <td>130</td>\n",
       "      <td>283</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48</td>\n",
       "      <td>F</td>\n",
       "      <td>138</td>\n",
       "      <td>214</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54</td>\n",
       "      <td>M</td>\n",
       "      <td>150</td>\n",
       "      <td>195</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age Sex  Blood Pressure  Cholesterol  Heart Rate  Diabetes  Family History  \\\n",
       "0   40   M             140          289         NaN       NaN             NaN   \n",
       "1   49   F             160          180         NaN       NaN             NaN   \n",
       "2   37   M             130          283         NaN       NaN             NaN   \n",
       "3   48   F             138          214         NaN       NaN             NaN   \n",
       "4   54   M             150          195         NaN       NaN             NaN   \n",
       "\n",
       "   Smoking  Obesity  Alcohol Consumption  ...  Sedentary Hours Per Day Income  \\\n",
       "0      NaN      NaN                  NaN  ...                      NaN    NaN   \n",
       "1      NaN      NaN                  NaN  ...                      NaN    NaN   \n",
       "2      NaN      NaN                  NaN  ...                      NaN    NaN   \n",
       "3      NaN      NaN                  NaN  ...                      NaN    NaN   \n",
       "4      NaN      NaN                  NaN  ...                      NaN    NaN   \n",
       "\n",
       "   BMI  Triglycerides  Physical Activity Days Per Week  Sleep Hours Per Day  \\\n",
       "0  NaN            NaN                              NaN                  NaN   \n",
       "1  NaN            NaN                              NaN                  NaN   \n",
       "2  NaN            NaN                              NaN                  NaN   \n",
       "3  NaN            NaN                              NaN                  NaN   \n",
       "4  NaN            NaN                              NaN                  NaN   \n",
       "\n",
       "   Country  Continent  Hemisphere  Heart Risk  \n",
       "0      NaN        NaN         NaN           0  \n",
       "1      NaN        NaN         NaN           1  \n",
       "2      NaN        NaN         NaN           0  \n",
       "3      NaN        NaN         NaN           1  \n",
       "4      NaN        NaN         NaN           0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 32 ms (started: 2023-12-10 21:04:34 -05:00)\n"
     ]
    }
   ],
   "source": [
    "file_path = r\"C:\\Users\\aaron\\Documents\\Python Code\\Datasets\\Heart Risk Combined Final Dataset.csv\"\n",
    "\n",
    "heart_attack = pd.read_csv(file_path)\n",
    "\n",
    "heart_attack.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0 ns (started: 2023-12-10 21:04:34 -05:00)\n"
     ]
    }
   ],
   "source": [
    "#Defining mapping function to map multiple inputs of the dataset\n",
    "def gender_map(x):\n",
    "    return x.map({'M': 1, 'F': 0, 'Male' : 1, \"Female\" : 0, '1' : 1, '0' : 0})\n",
    "\n",
    "def hemisphere_map(x):\n",
    "    return x.map({'Southern Hemisphere' : -1, 'Northern Hemisphere' : 1})\n",
    "\n",
    "def countries_map(x):\n",
    "    return x.map({'Argentina' : -1, 'Brazil' : -1, 'China' : -1, 'Colombia' : -1,\n",
    "    'India' : -1, 'Nigeria' : -1, 'South Africa' : -1, 'South Korea' : -1, 'Thailand' : -1,\n",
    "    'Vietnam' : -1, 'Australia' : 1, 'Canada' : 1, 'France' : 1, 'Germany' : 1,\n",
    "    'Italy' : 1, 'Japan' : 1, 'New Zealand' : 1, 'Spain' : 1, 'United Kingdom' : 1,\n",
    "    'United States' : 1})\n",
    "\n",
    "def diet_map(x):\n",
    "    return x.map({'Unhealthy' : -1, 'Average' : 0, 'Healthy' : 1})\n",
    "\n",
    "def continent_map(x):\n",
    "    return x.map({'Asia' : 0, 'Africa' : 1, 'Europe' : 2, 'North America' : 3,\n",
    "    'South America' : 4, 'Australia' : 5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0]\n",
      "[nan -1.  1.]\n",
      "[nan -1.  1.]\n",
      "[nan  0. -1.  1.]\n",
      "[nan  4.  3.  2.  0.  1.  5.]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Blood Pressure</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>Heart Rate</th>\n",
       "      <th>Diabetes</th>\n",
       "      <th>Family History</th>\n",
       "      <th>Smoking</th>\n",
       "      <th>Obesity</th>\n",
       "      <th>Alcohol Consumption</th>\n",
       "      <th>...</th>\n",
       "      <th>Sedentary Hours Per Day</th>\n",
       "      <th>Income</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Triglycerides</th>\n",
       "      <th>Physical Activity Days Per Week</th>\n",
       "      <th>Sleep Hours Per Day</th>\n",
       "      <th>Country</th>\n",
       "      <th>Continent</th>\n",
       "      <th>Hemisphere</th>\n",
       "      <th>Heart Risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>140</td>\n",
       "      <td>289</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>160</td>\n",
       "      <td>180</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>283</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>138</td>\n",
       "      <td>214</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>195</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Sex  Blood Pressure  Cholesterol  Heart Rate  Diabetes  \\\n",
       "0   40    1             140          289         NaN       NaN   \n",
       "1   49    0             160          180         NaN       NaN   \n",
       "2   37    1             130          283         NaN       NaN   \n",
       "3   48    0             138          214         NaN       NaN   \n",
       "4   54    1             150          195         NaN       NaN   \n",
       "\n",
       "   Family History  Smoking  Obesity  Alcohol Consumption  ...  \\\n",
       "0             NaN      NaN      NaN                  NaN  ...   \n",
       "1             NaN      NaN      NaN                  NaN  ...   \n",
       "2             NaN      NaN      NaN                  NaN  ...   \n",
       "3             NaN      NaN      NaN                  NaN  ...   \n",
       "4             NaN      NaN      NaN                  NaN  ...   \n",
       "\n",
       "   Sedentary Hours Per Day  Income  BMI  Triglycerides  \\\n",
       "0                      NaN     NaN  NaN            NaN   \n",
       "1                      NaN     NaN  NaN            NaN   \n",
       "2                      NaN     NaN  NaN            NaN   \n",
       "3                      NaN     NaN  NaN            NaN   \n",
       "4                      NaN     NaN  NaN            NaN   \n",
       "\n",
       "   Physical Activity Days Per Week  Sleep Hours Per Day  Country  Continent  \\\n",
       "0                              NaN                  NaN      NaN        NaN   \n",
       "1                              NaN                  NaN      NaN        NaN   \n",
       "2                              NaN                  NaN      NaN        NaN   \n",
       "3                              NaN                  NaN      NaN        NaN   \n",
       "4                              NaN                  NaN      NaN        NaN   \n",
       "\n",
       "   Hemisphere  Heart Risk  \n",
       "0         NaN           0  \n",
       "1         NaN           1  \n",
       "2         NaN           0  \n",
       "3         NaN           1  \n",
       "4         NaN           0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 15 ms (started: 2023-12-10 21:04:34 -05:00)\n"
     ]
    }
   ],
   "source": [
    "heart_attack['Sex'] = heart_attack[['Sex']].apply(gender_map)\n",
    "heart_attack['Hemisphere'] = heart_attack[['Hemisphere']].apply(hemisphere_map)\n",
    "heart_attack['Country'] = heart_attack[['Country']].apply(countries_map)\n",
    "heart_attack['Diet'] = heart_attack[['Diet']].apply(diet_map)\n",
    "heart_attack['Continent'] = heart_attack[['Continent']].apply(continent_map)\n",
    "\n",
    "unique_sex = heart_attack['Sex'].unique()\n",
    "print(unique_sex)\n",
    "unique = heart_attack['Hemisphere'].unique()\n",
    "print(unique)\n",
    "unique_country = heart_attack['Country'].unique()\n",
    "print(unique_country)\n",
    "unique_diet = heart_attack['Diet'].unique()\n",
    "print(unique_diet)\n",
    "unique_continent = heart_attack['Continent'].unique()\n",
    "print(unique_continent)\n",
    "\n",
    "heart_attack.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0]\n",
      "[ 1. -1.]\n",
      "[ 1. -1.]\n",
      "[ 1.  0. -1.]\n",
      "[0. 4. 3. 2. 1. 5.]\n",
      "Columns with NaN values after fillna operations:\n",
      "[]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Blood Pressure</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>Heart Rate</th>\n",
       "      <th>Diabetes</th>\n",
       "      <th>Family History</th>\n",
       "      <th>Smoking</th>\n",
       "      <th>Obesity</th>\n",
       "      <th>Alcohol Consumption</th>\n",
       "      <th>...</th>\n",
       "      <th>Sedentary Hours Per Day</th>\n",
       "      <th>Income</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Triglycerides</th>\n",
       "      <th>Physical Activity Days Per Week</th>\n",
       "      <th>Sleep Hours Per Day</th>\n",
       "      <th>Country</th>\n",
       "      <th>Continent</th>\n",
       "      <th>Hemisphere</th>\n",
       "      <th>Heart Risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>140</td>\n",
       "      <td>289</td>\n",
       "      <td>75.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.99369</td>\n",
       "      <td>157866.0</td>\n",
       "      <td>28.891446</td>\n",
       "      <td>417.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.023508</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>160</td>\n",
       "      <td>180</td>\n",
       "      <td>75.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.99369</td>\n",
       "      <td>157866.0</td>\n",
       "      <td>28.891446</td>\n",
       "      <td>417.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.023508</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>283</td>\n",
       "      <td>75.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.99369</td>\n",
       "      <td>157866.0</td>\n",
       "      <td>28.891446</td>\n",
       "      <td>417.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.023508</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>138</td>\n",
       "      <td>214</td>\n",
       "      <td>75.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.99369</td>\n",
       "      <td>157866.0</td>\n",
       "      <td>28.891446</td>\n",
       "      <td>417.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.023508</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>195</td>\n",
       "      <td>75.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.99369</td>\n",
       "      <td>157866.0</td>\n",
       "      <td>28.891446</td>\n",
       "      <td>417.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.023508</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Sex  Blood Pressure  Cholesterol  Heart Rate  Diabetes  \\\n",
       "0   40    1             140          289        75.0       1.0   \n",
       "1   49    0             160          180        75.0       1.0   \n",
       "2   37    1             130          283        75.0       1.0   \n",
       "3   48    0             138          214        75.0       1.0   \n",
       "4   54    1             150          195        75.0       1.0   \n",
       "\n",
       "   Family History  Smoking  Obesity  Alcohol Consumption  ...  \\\n",
       "0             0.0      1.0      1.0                  1.0  ...   \n",
       "1             0.0      1.0      1.0                  1.0  ...   \n",
       "2             0.0      1.0      1.0                  1.0  ...   \n",
       "3             0.0      1.0      1.0                  1.0  ...   \n",
       "4             0.0      1.0      1.0                  1.0  ...   \n",
       "\n",
       "   Sedentary Hours Per Day    Income        BMI  Triglycerides  \\\n",
       "0                  5.99369  157866.0  28.891446          417.0   \n",
       "1                  5.99369  157866.0  28.891446          417.0   \n",
       "2                  5.99369  157866.0  28.891446          417.0   \n",
       "3                  5.99369  157866.0  28.891446          417.0   \n",
       "4                  5.99369  157866.0  28.891446          417.0   \n",
       "\n",
       "   Physical Activity Days Per Week  Sleep Hours Per Day  Country  Continent  \\\n",
       "0                              3.0             7.023508      1.0        0.0   \n",
       "1                              3.0             7.023508      1.0        0.0   \n",
       "2                              3.0             7.023508      1.0        0.0   \n",
       "3                              3.0             7.023508      1.0        0.0   \n",
       "4                              3.0             7.023508      1.0        0.0   \n",
       "\n",
       "   Hemisphere  Heart Risk  \n",
       "0         1.0           0  \n",
       "1         1.0           1  \n",
       "2         1.0           0  \n",
       "3         1.0           1  \n",
       "4         1.0           0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 16 ms (started: 2023-12-10 21:04:34 -05:00)\n"
     ]
    }
   ],
   "source": [
    "mode_columns = ['Stress Level','Medication Use', 'Previous Heart Problems', 'Diet', 'Physical Activity Days Per Week', 'Alcohol Consumption', 'Obesity', 'Smoking', \n",
    "                'Family History', 'Diabetes', 'Hemisphere', 'Continent', 'Country']\n",
    "\n",
    "mean_columns = ['Exercise Hours Per Week', 'Sleep Hours Per Day', 'BMI', 'Sedentary Hours Per Day']\n",
    "\n",
    "median_columns = ['Heart Rate', 'Income', 'Triglycerides']\n",
    "\n",
    "# Fill NaN values with the mode of the column for mode_columns\n",
    "for col in mode_columns:\n",
    "    heart_attack[col].fillna(heart_attack[col].mode()[0], inplace=True)\n",
    "\n",
    "# Fill NaN values with the median of the column for median_columns\n",
    "for col in median_columns:\n",
    "    heart_attack[col].fillna(heart_attack[col].median(), inplace=True)\n",
    "\n",
    "# Fill NaN values with the mean of the column for mean_columns\n",
    "for col in mean_columns:\n",
    "    heart_attack[col].fillna(heart_attack[col].mean(), inplace=True)\n",
    "\n",
    "\n",
    "unique_sex = heart_attack['Sex'].unique()\n",
    "print(unique_sex)\n",
    "unique = heart_attack['Hemisphere'].unique()\n",
    "print(unique)\n",
    "unique_country = heart_attack['Country'].unique()\n",
    "print(unique_country)\n",
    "unique_diet = heart_attack['Diet'].unique()\n",
    "print(unique_diet)\n",
    "unique_continent = heart_attack['Continent'].unique()\n",
    "print(unique_continent)\n",
    "\n",
    "\n",
    "# Check for NaN values in columns after fillna operations\n",
    "columns_with_nulls = heart_attack.columns[heart_attack.isnull().any()].tolist()\n",
    "print(\"Columns with NaN values after fillna operations:\")\n",
    "print(columns_with_nulls)\n",
    "\n",
    "heart_attack.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is not available, using CPU.\n",
      "time: 0 ns (started: 2023-12-10 21:04:34 -05:00)\n"
     ]
    }
   ],
   "source": [
    "# Check if GPU is available\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")  # Use GPU\n",
    "    print(\"GPU is available.\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")   # Use CPU\n",
    "    print(\"GPU is not available, using CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n",
      "torch.float32\n",
      "time: 0 ns (started: 2023-12-10 21:04:34 -05:00)\n"
     ]
    }
   ],
   "source": [
    "#Splitting the Variables into X and Y\n",
    "X = heart_attack.iloc[:, 0:23].values\n",
    "Y = heart_attack.iloc[:, 24].values\n",
    "\n",
    "# Split our Data set into Training Data and val Data.\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size = 0.2, random_state = 0)\n",
    "\n",
    "Y_train = Y_train.reshape(-1, 1)\n",
    "Y_val = Y_val.reshape(-1, 1)\n",
    "\n",
    "# Convert the numpy arrays into tensors\n",
    "Y_train_t = torch.tensor(Y_train, dtype=torch.float)\n",
    "Y_val_t = torch.tensor(Y_val, dtype=torch.float)\n",
    "\n",
    "\n",
    "print(Y_train_t.dtype)\n",
    "print(Y_val_t.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0 ns (started: 2023-12-10 21:04:34 -05:00)\n"
     ]
    }
   ],
   "source": [
    "# Defining PCA function\n",
    "def PCA_function(X_train, X_val, K):\n",
    "  pca = PCA(n_components=K)\n",
    "  X_train_PCA = pca.fit_transform(X_train)\n",
    "  X_val_PCA = pca.fit_transform(X_val)\n",
    "  return X_train_PCA, X_val_PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of X_train after PCA is (7987, 2)\n",
      "The shape of X_val after PCA is (1997, 2)\n",
      "\n",
      "The shape of the X_train tensor is torch.Size([7987, 2])\n",
      "The shape of the X_val tensor is torch.Size([1997, 2])\n",
      "time: 16 ms (started: 2023-12-10 21:04:34 -05:00)\n"
     ]
    }
   ],
   "source": [
    "# Using the PCA function we defined to condense the inputs into 2 features\n",
    "(X_train_PCA, X_val_PCA) = PCA_function(X_train, X_val, 2)\n",
    "\n",
    "print(\"The shape of X_train after PCA is\", X_train_PCA.shape)\n",
    "print(\"The shape of X_val after PCA is\", X_val_PCA.shape)\n",
    "\n",
    "# Use standard scaling from Sklearn to scale data between - and  for better accuracy.\n",
    "scale = StandardScaler()\n",
    "X_train_PCA = scale.fit_transform(X_train_PCA)\n",
    "X_val_PCA = scale.fit_transform(X_val_PCA)\n",
    "\n",
    "X_train_PCA_t = torch.tensor(X_train_PCA, dtype=torch.float)\n",
    "X_val_PCA_t = torch.tensor(X_val_PCA, dtype=torch.float)\n",
    "\n",
    "print(\"\\nThe shape of the X_train tensor is\", X_train_PCA_t.shape)\n",
    "print(\"The shape of the X_val tensor is\", X_val_PCA_t.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0 ns (started: 2023-12-10 21:04:34 -05:00)\n"
     ]
    }
   ],
   "source": [
    "# Defining all the functions needed for training the linear model\n",
    "\n",
    "def model_linear(t_in, w1, w2, w3, b):\n",
    "  t_p = ((w3 * t_in ** 3) + (w2 * t_in ** 2) + (w1 * t_in) + b)\n",
    "  return t_p\n",
    "\n",
    "def loss_fn(t_p, t_gnd):\n",
    "  squared_diffs = (t_p - t_gnd)**2\n",
    "  return squared_diffs.mean()\n",
    "\n",
    "def training_loop(n_epochs, optimizer, params, train_t_in, val_t_in,\n",
    "                    train_t_out, val_t_out):\n",
    "  for epoch in range(1, n_epochs + 1):\n",
    "\n",
    "    if params.grad is not None:\n",
    "      params.grad.zero_()\n",
    "\n",
    "    train_t_p = model_linear(train_t_in, *params)\n",
    "    train_loss = loss_fn(train_t_p, train_t_out)\n",
    "\n",
    "    val_t_p = model_linear(val_t_in, *params)\n",
    "    val_loss = loss_fn(val_t_p, val_t_out)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    train_loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch <= 3 or epoch % 500 == 0:\n",
    "      print(f\"Epoch {epoch}, \\tTraining loss {train_loss.item():.4f},\"\n",
    "      f\" \\tValidation loss {val_loss.item():.4f}\")\n",
    "\n",
    "  return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss every 500 epochs using learning rate of 1e-3\n",
      "\n",
      "Epoch 1, \tTraining loss 12.1368, \tValidation loss 11.7982\n",
      "Epoch 2, \tTraining loss 11.8755, \tValidation loss 11.5454\n",
      "Epoch 3, \tTraining loss 11.6204, \tValidation loss 11.2984\n",
      "Epoch 500, \tTraining loss 0.4054, \tValidation loss 0.3959\n",
      "Epoch 1000, \tTraining loss 0.3196, \tValidation loss 0.3155\n",
      "Epoch 1500, \tTraining loss 0.2811, \tValidation loss 0.2791\n",
      "Epoch 2000, \tTraining loss 0.2620, \tValidation loss 0.2610\n",
      "Epoch 2500, \tTraining loss 0.2521, \tValidation loss 0.2515\n",
      "Epoch 3000, \tTraining loss 0.2465, \tValidation loss 0.2461\n",
      "Epoch 3500, \tTraining loss 0.2432, \tValidation loss 0.2429\n",
      "Epoch 4000, \tTraining loss 0.2411, \tValidation loss 0.2408\n",
      "Epoch 4500, \tTraining loss 0.2397, \tValidation loss 0.2393\n",
      "Epoch 5000, \tTraining loss 0.2387, \tValidation loss 0.2383\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 0.1219, -0.0076, -0.0511,  0.3853], requires_grad=True)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.33 s (started: 2023-12-10 21:04:34 -05:00)\n"
     ]
    }
   ],
   "source": [
    "# Calling the linear model\n",
    "\n",
    "params = torch.tensor([1.0, 1.0, 1.0, 0.0], requires_grad=True)\n",
    "\n",
    "learning_rate_1 = 1e-3\n",
    "optimizer_1 = optim.SGD([params], lr=learning_rate_1)\n",
    "\n",
    "print('Loss every 500 epochs using learning rate of 1e-3\\n')\n",
    "training_loop(\n",
    "    n_epochs = 5000,\n",
    "    optimizer = optimizer_1,\n",
    "    params = params,\n",
    "    train_t_in = X_train_PCA_t,\n",
    "    val_t_in = X_val_PCA_t,\n",
    "    train_t_out = Y_train_t,\n",
    "    val_t_out = Y_val_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.4973\n",
      "Training Precision: 0.4837\n",
      "Training Recall: 0.4830\n",
      "Training F1 Score: 0.4833\n",
      "\n",
      "Validation Accuracy: 0.5333\n",
      "Validation Precision: 0.5428\n",
      "Validation Recall: 0.5452\n",
      "Validation F1 Score: 0.5440\n",
      "time: 15 ms (started: 2023-12-10 21:04:37 -05:00)\n"
     ]
    }
   ],
   "source": [
    "# Getting the predictions based on the training set using the linear model\n",
    "model_output = model_linear(X_train_PCA_t, *params)\n",
    "# Converting the prediction tensor into a numpy array to use the sklearn metrics library\n",
    "model_output_np = model_output.detach().numpy() if isinstance(model_output, torch.Tensor) else model_output\n",
    "\n",
    "# Using argmax to get the class (1 or 0) with the highest probability\n",
    "predicted_labels = np.argmax(model_output_np, axis=1)\n",
    "\n",
    "# Calculate accuracy, precision, and recall for training set\n",
    "train_accuracy = accuracy_score(Y_train, predicted_labels)\n",
    "train_recall = recall_score(Y_train, predicted_labels, average= 'macro', zero_division=1)\n",
    "train_precision = precision_score(Y_train, predicted_labels, average = 'macro', zero_division=1)\n",
    "train_F1_score = (2*train_recall*train_precision)/(train_recall+train_precision)\n",
    "\n",
    "# Getting the predictions based on the validation set using the linear model\n",
    "model_output_val = model_linear(X_val_PCA_t, *params)\n",
    "# Converting the prediction tensor into a numpy array to use the sklearn metrics library\n",
    "model_output_val_np = model_output_val.detach().numpy() if isinstance(model_output_val, torch.Tensor) else model_output_val\n",
    "\n",
    "# Using argmax to get the class (1 or 0) with the highest probability\n",
    "predicted_labels_val = np.argmax(model_output_val_np, axis=1)\n",
    "\n",
    "# Calculate accuracy, precision, and recall for validation set\n",
    "val_accuracy = accuracy_score(Y_val, predicted_labels_val)\n",
    "val_precision = precision_score(Y_val, predicted_labels_val, average = 'macro', zero_division=1)\n",
    "val_recall = recall_score(Y_val, predicted_labels_val, average = 'macro', zero_division=1)\n",
    "val_F1_score = (2*val_recall*val_precision)/(val_recall+val_precision)\n",
    "\n",
    "# Print the calculated metrics\n",
    "print(f\"Training Accuracy: {train_accuracy:.4f}\")\n",
    "print(f\"Training Precision: {train_precision:.4f}\")\n",
    "print(f\"Training Recall: {train_recall:.4f}\")\n",
    "print(f\"Training F1 Score: {train_F1_score:.4f}\")\n",
    "\n",
    "print(f\"\\nValidation Accuracy: {val_accuracy:.4f}\")\n",
    "print(f\"Validation Precision: {val_precision:.4f}\")\n",
    "print(f\"Validation Recall: {val_recall:.4f}\")\n",
    "print(f\"Validation F1 Score: {val_F1_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=2, out_features=1024, bias=True)\n",
       "  (1): Tanh()\n",
       "  (2): Linear(in_features=1024, out_features=2048, bias=True)\n",
       "  (3): Tanh()\n",
       "  (4): Linear(in_features=2048, out_features=512, bias=True)\n",
       "  (5): Tanh()\n",
       "  (6): Linear(in_features=512, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 31 ms (started: 2023-12-10 21:04:37 -05:00)\n"
     ]
    }
   ],
   "source": [
    "# Sequential Model\n",
    "\n",
    "model_seq = nn.Sequential(\n",
    "    nn.Linear(2, 1024),\n",
    "    nn.Tanh(),\n",
    "    nn.Linear(1024, 2048),\n",
    "    nn.Tanh(),\n",
    "    nn.Linear(2048, 512),\n",
    "    nn.Tanh(),\n",
    "    nn.Linear(512, 1)\n",
    "            )\n",
    "model_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3151873"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0 ns (started: 2023-12-10 21:04:37 -05:00)\n"
     ]
    }
   ],
   "source": [
    "sum([p.numel() for p in model_seq.parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0 ns (started: 2023-12-10 21:04:37 -05:00)\n"
     ]
    }
   ],
   "source": [
    "#Let's define our training loop that will be used\n",
    "\n",
    "def training_loop_seq(n_epochs, optimizer, model, loss_fn, x_train, x_val,\n",
    "                  y_train, y_val):\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        p_train = model(x_train) # <1>\n",
    "        loss_train = loss_fn(p_train, y_train,)\n",
    "\n",
    "        p_val = model(x_val) # <1>\n",
    "        loss_val = loss_fn(p_val, y_val)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss_train.backward() # <2>\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "        if epoch == 1 or epoch % 10 == 0:\n",
    "            print(f\"Epoch: {epoch}, Training loss: {loss_train.item():.4f},\"\n",
    "                  f\" Validation loss: {loss_val.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Training loss: 0.3641, Validation loss: 0.3591\n",
      "Epoch: 10, Training loss: 0.2446, Validation loss: 0.2442\n",
      "Epoch: 20, Training loss: 0.2359, Validation loss: 0.2342\n",
      "Epoch: 30, Training loss: 0.2383, Validation loss: 0.2364\n",
      "Epoch: 40, Training loss: 0.2363, Validation loss: 0.2347\n",
      "Epoch: 50, Training loss: 0.2354, Validation loss: 0.2341\n",
      "Epoch: 60, Training loss: 0.2353, Validation loss: 0.2341\n",
      "Epoch: 70, Training loss: 0.2352, Validation loss: 0.2341\n",
      "Epoch: 80, Training loss: 0.2352, Validation loss: 0.2340\n",
      "Epoch: 90, Training loss: 0.2352, Validation loss: 0.2340\n",
      "Epoch: 100, Training loss: 0.2351, Validation loss: 0.2339\n",
      "Epoch: 110, Training loss: 0.2351, Validation loss: 0.2339\n",
      "Epoch: 120, Training loss: 0.2351, Validation loss: 0.2339\n",
      "Epoch: 130, Training loss: 0.2350, Validation loss: 0.2338\n",
      "Epoch: 140, Training loss: 0.2350, Validation loss: 0.2338\n",
      "Epoch: 150, Training loss: 0.2350, Validation loss: 0.2337\n",
      "time: 1min 43s (started: 2023-12-10 21:04:37 -05:00)\n"
     ]
    }
   ],
   "source": [
    "#Let's try doing some training\n",
    "\n",
    "optimizer_1 = optim.Adam(model_seq.parameters(), lr=1e-4)\n",
    "\n",
    "training_loop_seq(\n",
    "    n_epochs = 151,\n",
    "    optimizer = optimizer_1,\n",
    "    model = model_seq,\n",
    "    loss_fn = nn.MSELoss(),\n",
    "    x_train = X_train_PCA_t,\n",
    "    x_val = X_val_PCA_t,\n",
    "    y_train = Y_train_t,\n",
    "    y_val = Y_val_t\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0 ns (started: 2023-12-10 21:06:20 -05:00)\n"
     ]
    }
   ],
   "source": [
    "# Function to calculate accuracy\n",
    "def calculate_accuracy(predictions, targets):\n",
    "    return (predictions == targets).float().mean().item()\n",
    "\n",
    "# Function to calculate recall\n",
    "def calculate_recall(predictions, targets):\n",
    "    true_positives = ((predictions == 1) & (targets == 1)).sum().item()\n",
    "    false_negatives = ((predictions == 0) & (targets == 1)).sum().item()\n",
    "    return true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0\n",
    "\n",
    "# Function to calculate precision\n",
    "def calculate_precision(predictions, targets):\n",
    "    true_positives = ((predictions == 1) & (targets == 1)).sum().item()\n",
    "    false_positives = ((predictions == 1) & (targets == 0)).sum().item()\n",
    "    return true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.3825\n",
      "Training Recall: 1.0000\n",
      "Training Precision: 0.3825\n",
      "Training F1 Score: 0.5533\n",
      "\n",
      "Validation Accuracy: 0.3791\n",
      "Validation Recall: 1.0000\n",
      "Validation Precision: 0.3791\n",
      "Validation F1 Score: 0.5497\n",
      "time: 281 ms (started: 2023-12-10 21:06:20 -05:00)\n"
     ]
    }
   ],
   "source": [
    "# Calculate predictions for the training set\n",
    "with torch.no_grad():\n",
    "    train_predictions = torch.round(torch.sigmoid(model_seq(X_train_PCA_t)))\n",
    "\n",
    "# Calculate accuracy, recall, precision, and F1 Score for the training set\n",
    "accuracy_train = calculate_accuracy(train_predictions, Y_train_t)\n",
    "recall_train = calculate_recall(train_predictions, Y_train_t)\n",
    "precision_train = calculate_precision(train_predictions, Y_train_t)\n",
    "F1_score_train = (2*recall_train*precision_train)/(recall_train+precision_train)\n",
    "\n",
    "# Calculate predictions for the validation set\n",
    "with torch.no_grad():\n",
    "    train_predictions_val = torch.round(torch.sigmoid(model_seq(X_val_PCA_t)))\n",
    "\n",
    "# Calculate accuracy, recall, precision, and F1 Score for the validation set\n",
    "accuracy_val = calculate_accuracy(train_predictions_val, Y_val_t)\n",
    "recall_val = calculate_recall(train_predictions_val, Y_val_t)\n",
    "precision_val = calculate_precision(train_predictions_val, Y_val_t)\n",
    "F1_score_val = (2*recall_val*precision_val)/(recall_val+precision_val)\n",
    "\n",
    "# Print the calculated metrics\n",
    "print(\"Training Accuracy: {:.4f}\".format(accuracy_train))\n",
    "print(\"Training Recall: {:.4f}\".format(recall_train))\n",
    "print(\"Training Precision: {:.4f}\".format(precision_train))\n",
    "print(\"Training F1 Score: {:.4f}\".format(F1_score_train))\n",
    "\n",
    "print(\"\\nValidation Accuracy: {:.4f}\".format(accuracy_val))\n",
    "print(\"Validation Recall: {:.4f}\".format(recall_val))\n",
    "print(\"Validation Precision: {:.4f}\".format(precision_val))\n",
    "print(\"Validation F1 Score: {:.4f}\".format(F1_score_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 16 ms (started: 2023-12-10 21:06:20 -05:00)\n"
     ]
    }
   ],
   "source": [
    "model_fnn = nn.Sequential(\n",
    "            nn.Linear(2, 1024),\n",
    "            nn.Tanh(),\n",
    "            nn.Dropout(p=0.5),  # Dropout layer with a dropout probability of 0.5\n",
    "            nn.Linear(1024, 2048),\n",
    "            nn.Tanh(),\n",
    "            nn.Dropout(p=0.5),  # Dropout layer with a dropout probability of 0.5\n",
    "            nn.Linear(2048,1024),\n",
    "            nn.Tanh(),\n",
    "            nn.Dropout(p=0.5),  # Dropout layer with a dropout probability of 0.5\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.Tanh(),\n",
    "            nn.Dropout(p=0.5),  # Dropout layer with a dropout probability of 0.5\n",
    "            nn.Linear(512, 64),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(64, 1)\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4758145"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 15 ms (started: 2023-12-10 21:06:20 -05:00)\n"
     ]
    }
   ],
   "source": [
    "sum([p.numel() for p in model_fnn.parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 0.687828\n",
      "Epoch: 10, Loss: 0.666923\n",
      "Epoch: 20, Loss: 0.666157\n",
      "Epoch: 30, Loss: 0.664906\n",
      "Epoch: 40, Loss: 0.665643\n",
      "Epoch: 50, Loss: 0.664982\n",
      "Epoch: 60, Loss: 0.665459\n",
      "Epoch: 70, Loss: 0.665062\n",
      "Epoch: 80, Loss: 0.664465\n",
      "Epoch: 90, Loss: 0.664202\n",
      "Epoch: 100, Loss: 0.664330\n",
      "Epoch: 110, Loss: 0.664178\n",
      "Epoch: 120, Loss: 0.664371\n",
      "Epoch: 130, Loss: 0.664425\n",
      "Epoch: 140, Loss: 0.664458\n",
      "Epoch: 150, Loss: 0.663770\n",
      "time: 2min 24s (started: 2023-12-10 21:06:20 -05:00)\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1\n",
    "\n",
    "optimizer = optim.SGD(model_fnn.parameters(), lr=learning_rate)\n",
    "\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "n_epochs = 151\n",
    "\n",
    "#This is the Training\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    outputs = model_fnn(X_train_PCA_t)\n",
    "    loss = loss_fn(outputs, Y_train_t)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 10 == 0:  # Print loss every 10 epochs\n",
    "      print(\"Epoch: %d, Loss: %f\" % (epoch, float(loss)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.617503\n",
      "Training Precision: 0.308752\n",
      "Training Recall: 0.500000\n",
      "Training F1 score: 0.381763\n",
      "time: 328 ms (started: 2023-12-10 21:08:45 -05:00)\n"
     ]
    }
   ],
   "source": [
    "# Checking the Accuracy, Recall, Precision, and F1 Score of the Training Set\n",
    "\n",
    "correct_train = 0\n",
    "total_train = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs_train = model_fnn(X_train_PCA_t)\n",
    "    _, predicted_train = torch.max(outputs_train, dim=1)\n",
    "    total_train += Y_train_t.size(0)\n",
    "    correct_train += int((predicted_train == Y_train_t.squeeze()).sum())\n",
    "\n",
    "accuracy_train = correct_train / total_train\n",
    "precision_train = precision_score(Y_train_t, predicted_train, average='macro', zero_division=0)\n",
    "recall_train = recall_score(Y_train_t, predicted_train, average='macro', zero_division=0)\n",
    "F1_score_train = (2*recall_train*precision_train)/(recall_train+precision_train)\n",
    "\n",
    "# Print the metrics\n",
    "print(\"Training Accuracy: %f\" % accuracy_train)\n",
    "print(\"Training Precision: %f\" % precision_train)\n",
    "print(\"Training Recall: %f\" % recall_train)\n",
    "print(\"Training F1 score: %f\" % F1_score_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.620931\n",
      "Training Precision: 0.310466\n",
      "Training Recall: 0.500000\n",
      "Training F1 score: 0.383071\n",
      "time: 78 ms (started: 2023-12-10 21:08:45 -05:00)\n"
     ]
    }
   ],
   "source": [
    "# Checking the Accuracy, Recall, Precision, and F1 Score of the Validation Set\n",
    "\n",
    "correct_val = 0\n",
    "total_val = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs_val = model_fnn(X_val_PCA_t)\n",
    "    _, predicted_val = torch.max(outputs_val, dim=1)\n",
    "    total_val += Y_val_t.size(0)\n",
    "    correct_val += int((predicted_val == Y_val_t.squeeze()).sum())\n",
    "\n",
    "accuracy_val = correct_val / total_val\n",
    "precision_val = precision_score(Y_val_t, predicted_val, average='macro', zero_division=0)\n",
    "recall_val = recall_score(Y_val_t, predicted_val, average='macro', zero_division=0)\n",
    "F1_score_val = (2*recall_val*precision_val)/(recall_val+precision_val)\n",
    "\n",
    "# Print the metrics\n",
    "print(\"Validation Accuracy: %f\" % accuracy_val)\n",
    "print(\"Training Precision: %f\" % precision_val)\n",
    "print(\"Training Recall: %f\" % recall_val)\n",
    "print(\"Training F1 score: %f\" % F1_score_val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
